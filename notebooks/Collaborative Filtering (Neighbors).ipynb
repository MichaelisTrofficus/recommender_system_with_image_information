{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df2ad75",
   "metadata": {},
   "source": [
    "Se determina el flujo completo que debe pasar el dato original hasta la obtención de las métricas de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14d07e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_ratings_matrix(data_rows: np.ndarray):\n",
    "    r = np.zeros((943, 1682))\n",
    "    r[:] = np.nan\n",
    "    for i in data_rows:\n",
    "        r[i[0] - 1][i[1] - 1] = i[2]\n",
    "    return r\n",
    "\n",
    "# Carga de datos de entrenamiento y test (el test es un 10% del entrenamiento en nuestro caso)\n",
    "train_ratings = pd.read_csv(\"../data/train.csv\")\n",
    "test_ratings = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbdc1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating  timestamp\n",
      "0       85      423       4  879454046\n",
      "1      290       71       5  880473667\n",
      "2      152      692       5  880149963\n"
     ]
    }
   ],
   "source": [
    "print(train_ratings.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0020322c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating  timestamp\n",
      "0      301       39       3  882076292\n",
      "1      288      121       2  886893063\n",
      "2      234      614       3  892334609\n"
     ]
    }
   ],
   "source": [
    "print(test_ratings.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2ff02",
   "metadata": {},
   "source": [
    "# Normalización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ec723",
   "metadata": {},
   "source": [
    "En este caso por ejemplo usamos Z Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3e86d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZScoreNormalization:\n",
    "    def __init__(self, user: bool = True):\n",
    "        self.user = user\n",
    "        self.means = []\n",
    "        self.stds = []\n",
    "\n",
    "    def transform(self, r: np.ndarray):\n",
    "        n_u, n_i = r.shape\n",
    "        if self.user:\n",
    "            self.means = np.hstack([np.reshape(np.nanmean(r, axis=1), (-1, 1))] * n_i)\n",
    "            self.stds = np.hstack([np.reshape(np.nanstd(r, axis=1), (-1, 1))] * n_i)\n",
    "        else:\n",
    "            self.means = np.vstack([np.reshape(np.nanmean(r, axis=0), (1, -1))] * n_u)\n",
    "            self.stds = np.vstack([np.reshape(np.nanstd(r, axis=0), (1, -1))] * n_u)\n",
    "\n",
    "        return (r - self.means) / self.stds\n",
    "\n",
    "    def reverse_transform(self, r: np.ndarray):\n",
    "        # We use hadamard product\n",
    "        return np.multiply(self.stds, r) + self.means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df693cfb",
   "metadata": {},
   "source": [
    "Convertimos los ratings de entrenamiento a una matriz de ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97801bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = generate_ratings_matrix(train_ratings.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e28fde20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  3.  4. ... nan nan nan]\n",
      " [ 4. nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [ 5. nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan  5. nan ... nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a52a2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_centered = ZScoreNormalization().transform(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd43534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.11297179 -0.50180231  0.30558474 ...         nan         nan\n",
      "          nan]\n",
      " [ 0.23036965         nan         nan ...         nan         nan\n",
      "          nan]\n",
      " [        nan         nan         nan ...         nan         nan\n",
      "          nan]\n",
      " ...\n",
      " [ 0.98149546         nan         nan ...         nan         nan\n",
      "          nan]\n",
      " [        nan         nan         nan ...         nan         nan\n",
      "          nan]\n",
      " [        nan  1.27155178         nan ...         nan         nan\n",
      "          nan]]\n"
     ]
    }
   ],
   "source": [
    "print(r_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a3d56e",
   "metadata": {},
   "source": [
    "# Cálculo del coeficiente de correlación de Pearson entre usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71ff8452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation(u: np.ndarray, v: np.ndarray):\n",
    "    \"\"\"\n",
    "    Computes the pearson correlation between two vectors\n",
    "    Args:\n",
    "        u: First vector\n",
    "        v: Second vector\n",
    "\n",
    "    Returns:\n",
    "        The pearson correlation value\n",
    "    \"\"\"\n",
    "\n",
    "    u_mean = np.nanmean(u)\n",
    "    v_mean = np.nanmean(v)\n",
    "\n",
    "    mean_deviation = (u - u_mean) * (v - v_mean)\n",
    "    num = np.nansum(mean_deviation)\n",
    "\n",
    "    # We can get the common elements from mean_deviation\n",
    "    common_indices = np.argwhere(~ np.isnan(mean_deviation))\n",
    "    u_common = u[common_indices]\n",
    "    v_common = v[common_indices]\n",
    "\n",
    "    den = np.sqrt(np.sum(np.square(u_common - u_mean)) * np.sum(np.square(v_common - v_mean)))\n",
    "    return num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e360682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.43it/s]/var/folders/83/9r8j1fgd24565dkqk6cy93480000gp/T/ipykernel_35671/2349031291.py:24: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return num / den\n",
      "943it [02:50,  5.54it/s]\n"
     ]
    }
   ],
   "source": [
    "sim_matrix = np.zeros((943, 943))\n",
    "\n",
    "for i, u in tqdm(enumerate(r_centered)):\n",
    "    for j, v in enumerate(r_centered):\n",
    "        sim_matrix[i][j] = pearson_correlation(u, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1142f26d",
   "metadata": {},
   "source": [
    "No vale hacerlo con el .corr() de pandas porque la lógica es distinta al calcular las desviaciones estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f280661e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.21493829,  0.13931314, ...,  0.22516616,\n",
       "        -0.15267653,  0.08732096],\n",
       "       [ 0.21493829,  1.        , -0.21903385, ..., -0.29904328,\n",
       "         0.203545  ,  0.14623625],\n",
       "       [ 0.13931314, -0.21903385,  1.        , ...,  0.83481571,\n",
       "         0.31565668,  0.12403473],\n",
       "       ...,\n",
       "       [ 0.22516616, -0.29904328,  0.83481571, ...,  1.        ,\n",
       "        -0.48163175,  0.07110123],\n",
       "       [-0.15267653,  0.203545  ,  0.31565668, ..., -0.48163175,\n",
       "         1.        ,  0.38047957],\n",
       "       [ 0.08732096,  0.14623625,  0.12403473, ...,  0.07110123,\n",
       "         0.38047957,  1.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95f29d",
   "metadata": {},
   "source": [
    "Guardamos la distancia para futuros procesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a720b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./sim_matrix.npy\", \"wb\") as f:\n",
    "    np.save(f, sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9a9fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./sim_matrix.npy\", \"rb\") as f:\n",
    "    sim_matrix = np.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680bd45e",
   "metadata": {},
   "source": [
    "Seleccionamos el número adecuado de vecinos cercanos al usuario activo (si lo hacemos para usuarios). Después, computamos el weighted rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33108d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
